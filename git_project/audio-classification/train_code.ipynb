{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding= UTF-8\n",
    "## training code(feat_extract)\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import soundfile as sf\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = sf.read(file_name, dtype='float32')\n",
    "    if X.ndim > 1:\n",
    "        X = X[:,0]\n",
    "    X = X.T\n",
    "\n",
    "    # short term fourier transform\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13).T,axis=0)\n",
    "    print('mfcc shape : {}'.format(mfccs.shape))\n",
    "    \n",
    "    # chroma\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    print('chroma shape : {}'.format(chroma.shape))\n",
    "\n",
    "\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    print('tonnetz shape : {}'.format(tonnetz.shape))\n",
    "    return mfccs,chroma,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features, labels = np.empty((0,31)), np.empty(0)\n",
    "    files_order = []\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print(sub_dir)\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            print(fn)\n",
    "            files_order.append(fn)\n",
    "            try:\n",
    "#                 mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "                 mfccs, chroma,tonnetz = extract_feature(fn)\n",
    "            except Exception as e:\n",
    "                print(\"[Error] extract feature error. %s\" % (e))\n",
    "                continue\n",
    "#             ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            ext_features = np.hstack([mfccs,chroma,tonnetz])\n",
    "            features = np.vstack([features,ext_features])\n",
    "            # labels = np.append(labels, fn.split('/')[1])\n",
    "            labels = np.append(labels, label)\n",
    "        print(\"extract %s features done\" % (sub_dir))\n",
    "    return np.array(features), np.array(labels, dtype = np.int), files_order\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "# Get features and labels\n",
    "r = os.listdir(\"./data/\")\n",
    "r.sort()\n",
    "features, labels, x= parse_audio_files('data', r)\n",
    "np.save('./feat.npy', features)\n",
    "np.save('./label.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding= UTF-8\n",
    "## using extracted feature, fit, predict(svm)\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from numpy file\n",
    "X =  np.load('feat.npy')\n",
    "y =  np.load('label.npy').ravel()\n",
    "print(y)\n",
    "\n",
    "def convert(x):\n",
    "    if x == 1:\n",
    "        return('song')\n",
    "    if x == 2:\n",
    "        return('speech')\n",
    "#     if x == 2:\n",
    "#         return('clap')\n",
    "\n",
    "y = np.array(list(map(convert , y)))\n",
    "print(y)\n",
    "print('originnal data count :{}'.format(len(X)))\n",
    "\n",
    "# Split data into training and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('train data count : {}'.format(len(X_train)))\n",
    "print('test data count : {}'.format(len(X_test)))\n",
    "\n",
    "\n",
    "# Simple SVM\n",
    "print('fitting...')\n",
    "clf = SVC(C=20.0,probability=True,kernel='rbf',class_weight = {'speech' :1, 'song' : 1}, gamma=0.00001)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = clf.score(X_test, y_test)\n",
    "print(\"acc=%0.3f\" % acc)\n",
    "print(pd.crosstab(y_pred, y_test))\n",
    "\n",
    "\n",
    "filename = 'svm.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# Grid search for best parameters\n",
    "# Set the parameters by cross-validation\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
    "#                      'C': [1, 10 ,20,30,40,50]}]\n",
    "#                     #  ,\n",
    "#                     # {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# scores = ['precision', 'recall']\n",
    "\n",
    "# for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     print('')\n",
    "\n",
    "#     clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "#                        scoring='%s_macro' % score)\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print('')\n",
    "#     print(clf.best_params_)\n",
    "#     print('')\n",
    "#     print(\"Grid scores on development set:\")\n",
    "#     print('')\n",
    "#     means = clf.cv_results_['mean_test_score']\n",
    "#     stds = clf.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#               % (mean, std * 2, params))\n",
    "#     print('')\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print('')\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print('')\n",
    "#     y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
